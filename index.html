<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Primary Meta Tags -->
  <title>SIGCoLED: Human-AI Collaborative Learning, Exploration, and Discovery</title>
  <meta name="title" content="SIGCoLED: Special Interest Group on Human-AI Collaborative Learning, Exploration, and Discovery">
  <meta name="description" content="An interdisciplinary research group focused on Generative AI & Human-AI Collaboration for education, scientific discovery, and creative work.">
  <meta name="keywords" content="human-AI collaboration, collaborative learning, AI for education, generative AI, human-centered AI, SIGCoLED">
  <meta name="author" content="SIGCoLED Research Group">
  <meta name="robots" content="index, follow">
  <meta name="google-site-verification" content="gEQQW3Rysd1uOa2M3W9man_Ub5ExM2PCxCyg6ZfSJLw" />
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <div class="header-content">
      <h1>SIGCoLED</h1>
      <p>Special Interest Group on Human-AI Collaborative Learning, Exploration, and Discovery</p>
    </div>
  </header>

  <nav>
    <div class="nav-container">
      <div class="mobile-menu-toggle">
        <span></span>
        <span></span>
        <span></span>
      </div>
      <ul class="nav-menu">
        <li><a href="#about">About</a></li>
        <li><a href="#research">Research</a></li>
        <li><a href="#team">People</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <div class="container">
    <section id="about">
      <h2>About SIGCoLED</h2>
      <p>
        SIGCoLED is an interdisciplinary research group focused on the frontier of Generative AI & Human-AI Collaboration. We bring together researchers and practitioners from various domains such as computer and information science, education, psychology, and human-computer interaction, to explore how humans and intelligent systems (not limited to LLMs) can effectively and efficiently learn from each other, and discover together.
      </p>
      <p>
        We are committed to open science principles, with the aim of enhancing human potential (both kids and adults) and improving the accessibility, reliability, and explainability of human-centered AI. Our research topics focus on real-world challenges in education, scientific discovery, creative work, and professional knowledge domains where human-AI collaboration can unlock new possibilities.
      </p>
    </section>

    <section id="research">
      <h2>Research Areas</h2>
      <div class="research-grid">
        <div class="research-card">
          <div class="research-img">
            <img src="assets/Images/Learning_Remix.png" alt="Image">
          </div>
          <div class="research-content">
            <h3>Learning</h3>
            <p>Developing intelligent systems that can both learn from and teach humans, creating interactive environments to support knowledge acquisition.</p>
          </div>
        </div>

        <div class="research-card">
          <div class="research-img">
            <img src="assets/Images/Exploration.png" alt="Image">
          </div>
          <div class="research-content">
            <h3>Exploration</h3>
            <p>Investigating how artificial intelligence expands human's capabilities and skills for new knowledge, or identifying novel directions and opportunities.</p>
          </div>
        </div>

        <div class="research-card">
          <div class="research-img">
            <img src="assets/Images/Discovery_V3.png" alt="Image">
          </div>
          <div class="research-content">
            <h3>Discovery</h3>
            <p>Combining computational pattern recognition with human's intuition to uncover insights in complex data, through synergistic human-AI collaboration.</p>
          </div>
        </div>
      </div>
    </section>

    <section id="publications">
      <h2>Selected Publications</h2>

      <div class="publications-list">
        <div class="publication-item">
          <p class="pub-title">Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions</p>
          <p class="pub-authors">Zhengyuan Liu, Stella Xin Yin, Carolyn Lee, Nancy F. Chen</p>
          <p class="pub-venue">In Proceedings of IEEE CAI 2024</p>
        </div>

        <div class="publication-item">
          <p class="pub-title">Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems</p>
          <p class="pub-authors">Zhengyuan Liu, Stella Xin Yin, Geyu Lin, Nancy F. Chen</p>
          <p class="pub-venue">In Proceedings of EMNLP 2024</p>
        </div>

        <div class="publication-item">
          <p class="pub-title">Understanding Determinants of Student Behavioral Intention in Singapore's AI Education: Insights from the Situated Expectancy-Value Theory</p>
          <p class="pub-authors">Stella Xin Yin, Dion Hoe-Lian Goh</p>
          <p class="pub-venue">Journal of Interactive Learning Environments, 2025</p>
        </div>

        <div class="publication-item">
          <p class="pub-title">Scaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Education</p>
          <p class="pub-authors">Stella Xin Yin, Zhengyuan Liu, Dion Hoe-Lian Goh, Choon Lang Quek, Nancy F. Chen</p>
          <p class="pub-venue">In Proceedings of Learning Analytics & Knowledge 2025</p>
        </div>

        <div class="publication-item">
          <p class="pub-title">Collaborative Learning in K-12 Computational Thinking Education: A Systematic Review</p>
          <p class="pub-authors">Stella Xin Yin, Dion Hoe-Lian Goh, Choon Lang Quek</p>
          <p class="pub-venue">Journal of Educational Computing Research, 2024</p>
        </div>

      </div>
    </section>

    <section id="team">
      <h2>People</h2>
      <p>Our interdisciplinary research brings together experts from diverse backgrounds:</p>

      <div class="team-grid">
        <div class="team-member">
          <div class="team-photo">
            <svg width="64" height="64" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
              <circle cx="12" cy="7" r="4"></circle>
            </svg>
          </div>
          <p><b>Zhengyuan Liu</b><br>Conversational AI,<br>Multi-modal Foundation Models</p>
        </div>

        <div class="team-member">
          <div class="team-photo">
            <img src="assets/Photos/Stella_Photo.png" alt="Photo" width="180px">
          </div>
          <p><b>Stella Xin Yin</b><br>Collaborative Learning,<br>Computational Thinking</p>
        </div>

        <div class="team-member">
          <div class="team-photo" >
            <img src="assets/Photos/Dion_Photo.png" alt="Photo" width="180px">
          </div>
          <p><b>Dion Hoe-Lian Goh</b><br>Information Seeking Behavior,<br>Game-based Learning</p>
        </div>

        <div class="team-member">
          <div class="team-photo">
            <img src="assets/Photos/Nancy_Photo.png" alt="Photo" width="180px">
          </div>
          <p><b>Nancy F. Chen</b><br>Multi-modal Generative AI<br>AI for Healthcare and Education</p>
        </div>
      </div>
    </section>

    <section id="contact">
      <h2>Contact Us</h2>
      <p>
        We're always open to collaborations, contributions, and research partnerships and discussions about SIGCoLED. If you're interested in exploring various opportunities, please get in touch.
        <strong>Email:</strong> zhengyua001@e.ntu.edu.sg, stellayin06@outlook.com<br>
      </p>
    </section>
  </div>

  <footer>
    <div class="footer-content">
      <div class="copyright">
        <p>All content on this website is provided for academic and educational purposes.</p>
        <p>&copy; 2025 SIGCoLED. All rights reserved.</p>
      </div>
    </div>
  </footer>

  <script>
    // Toggle mobile menu
    document.querySelector('.mobile-menu-toggle').addEventListener('click', function() {
      document.querySelector('.nav-menu').classList.toggle('active');
      this.classList.toggle('active');
    });

    // Handle smooth scrolling to section headings
    document.querySelectorAll('.nav-menu a').forEach(link => {
      link.addEventListener('click', function(e) {
        e.preventDefault();

        // Close mobile menu if open
        document.querySelector('.nav-menu').classList.remove('active');
        document.querySelector('.mobile-menu-toggle').classList.remove('active');

        // Get the target section id from href
        const targetId = this.getAttribute('href');
        const targetSection = document.querySelector(targetId);

        if (targetSection) {
          // Find the h2 element within the target section
          const targetHeading = targetSection.querySelector('h2');

          if (targetHeading) {
            // Calculate position accounting for the fixed navbar
            const navHeight = document.querySelector('nav').offsetHeight;
            const headingPosition = targetHeading.getBoundingClientRect().top + window.pageYOffset - navHeight - 20;

            // Scroll to the heading
            window.scrollTo({
              top: headingPosition,
              behavior: 'smooth'
            });
          }
        }
      });
    });
  </script>
</body>
</html>
